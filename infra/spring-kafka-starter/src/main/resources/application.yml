spring:
  kafka:
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:localhost:9092}

    # Schema Registry Configuration
    properties:
      schema.registry.url: ${KAFKA_SCHEMA_REGISTRY_URL:http://localhost:8081}
      # Uncomment and configure if authentication is needed
      # schema.registry.basic.auth.credentials.source: USER_INFO
      # schema.registry.basic.auth.user.info: ${KAFKA_SCHEMA_REGISTRY_USER:}:${KAFKA_SCHEMA_REGISTRY_PASSWORD:}

    # Producer Configuration
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: io.confluent.kafka.serializers.KafkaAvroSerializer
      # Exactly-once semantics
      properties:
        enable.idempotence: true
        acks: all
        retries: 2147483647
        max.in.flight.requests.per.connection: 5
        delivery.timeout.ms: 120000
        request.timeout.ms: 30000
        # Compression
        compression.type: snappy
        # Batching
        batch.size: 16384
        linger.ms: 5

    # Consumer Configuration
    consumer:
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: io.confluent.kafka.serializers.KafkaAvroDeserializer
      group-id: ${KAFKA_CONSUMER_GROUP_ID:default-group}
      auto-offset-reset: earliest
      enable-auto-commit: false
      properties:
        specific.avro.reader: true
        # Session timeout and heartbeat
        session.timeout.ms: 30000
        heartbeat.interval.ms: 3000
        # Fetch configuration
        fetch.min.bytes: 1
        fetch.max.wait.ms: 500
        max.poll.records: 500
        max.poll.interval.ms: 300000

    # Listener Configuration
    listener:
      ack-mode: manual_immediate
      concurrency: 3
      poll-timeout: 3000

# Management and Actuator
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: always
    prometheus:
      enabled: true
  metrics:
    export:
      prometheus:
        enabled: true
    distribution:
      percentiles:
        http.server.requests: 0.5, 0.95, 0.99
        spring.kafka.consumer: 0.5, 0.95, 0.99
        spring.kafka.producer: 0.5, 0.95, 0.99

# OpenTelemetry Tracing Configuration
otel:
  exporter:
    otlp:
      endpoint: ${OTEL_EXPORTER_OTLP_ENDPOINT:http://localhost:4317}
      headers: ${OTEL_EXPORTER_OTLP_HEADERS:}
  baggage:
    propagation:
      enabled: true
  traces:
    exporter: otlp
    sampler:
      probability: ${OTEL_TRACES_SAMPLER_PROBABILITY:1.0}

# Logging Configuration
logging:
  level:
    org.apache.kafka: INFO
    org.springframework.kafka: INFO
    io.confluent: INFO
    # Uncomment for debugging
    # org.apache.kafka.clients: DEBUG
    # org.springframework.kafka.listener: DEBUG
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"

# Application specific properties (can be overridden)
app:
  kafka:
    # Retry configuration
    retry:
      max-attempts: 3
      backoff-delay: 1000
    # Dead letter topic suffix
    dead-letter-suffix: .DLT
    # Topic configurations
    topics:
      # These will be overridden by specific services
      order-events: ${KAFKA_TOPIC_ORDER_EVENTS:order-events}
      payment-events: ${KAFKA_TOPIC_PAYMENT_EVENTS:payment-events}
      inventory-events: ${KAFKA_TOPIC_INVENTORY_EVENTS:inventory-events}
      shipping-events: ${KAFKA_TOPIC_SHIPPING_EVENTS:shipping-events}
